{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecaf0039",
   "metadata": {},
   "source": [
    "# Notebook 05: Model Training and Evaluation mit bereinigtem Datensatz\n",
    "\n",
    "In diesem Notebook werden der bereinigte Datensatz ohne `mmr` und redundante Features geladen, in Trainings- und Testset aufgeteilt und anschliessend zwei Baseline-Modelle (Lineare Regression und Random Forest) trainiert, mittels Kreuzvalidierung evaluiert und abschliessend auf dem Testset verglichen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a699107",
   "metadata": {},
   "source": [
    "## 1. Setup & Laden der Daten\n",
    "In diesem Kapitel werden alle benoetigten Bibliotheken importiert und der bereinigte Datensatz eingelesen sowie ein erster Ueberblick gegeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874d26a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des bereinigten DataFrames: (91562, 22)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>condition</th>\n",
       "      <th>odometer</th>\n",
       "      <th>sale_year</th>\n",
       "      <th>sale_month</th>\n",
       "      <th>sale_day</th>\n",
       "      <th>sale_weekday</th>\n",
       "      <th>body</th>\n",
       "      <th>transmission</th>\n",
       "      <th>color</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>has_sport</th>\n",
       "      <th>has_limited</th>\n",
       "      <th>has_lx</th>\n",
       "      <th>has_se</th>\n",
       "      <th>has_touring</th>\n",
       "      <th>has_premium</th>\n",
       "      <th>miles_per_year</th>\n",
       "      <th>color_popularity</th>\n",
       "      <th>sellingprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5559.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>automatic</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5559.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45035.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>SUV</td>\n",
       "      <td>automatic</td>\n",
       "      <td>gray</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22517.5</td>\n",
       "      <td>3</td>\n",
       "      <td>14100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>46.0</td>\n",
       "      <td>20035.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>SUV</td>\n",
       "      <td>automatic</td>\n",
       "      <td>gray</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10017.5</td>\n",
       "      <td>3</td>\n",
       "      <td>20800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41115.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>SUV</td>\n",
       "      <td>automatic</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20557.5</td>\n",
       "      <td>4</td>\n",
       "      <td>22100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26747.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>automatic</td>\n",
       "      <td>red</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13373.5</td>\n",
       "      <td>6</td>\n",
       "      <td>14000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  condition  odometer  sale_year  sale_month  sale_day  sale_weekday  \\\n",
       "0  2015        2.0    5559.0       2015           1        13             1   \n",
       "1  2012       35.0   45035.0       2014          12        18             3   \n",
       "2  2012       46.0   20035.0       2014          12        18             3   \n",
       "3  2012       46.0   41115.0       2014          12        18             3   \n",
       "4  2012        3.0   26747.0       2014          12        17             2   \n",
       "\n",
       "        body transmission  color  ...  season  has_sport has_limited  has_lx  \\\n",
       "0      Sedan    automatic  white  ...  Winter          0           0       0   \n",
       "1        SUV    automatic   gray  ...  Winter          0           1       0   \n",
       "2        SUV    automatic   gray  ...  Winter          0           0       0   \n",
       "3        SUV    automatic  white  ...  Winter          0           0       0   \n",
       "4  Hatchback    automatic    red  ...  Winter          0           0       0   \n",
       "\n",
       "   has_se  has_touring  has_premium  miles_per_year  color_popularity  \\\n",
       "0       1            0            0          5559.0                 4   \n",
       "1       0            0            0         22517.5                 3   \n",
       "2       1            0            0         10017.5                 3   \n",
       "3       1            0            0         20557.5                 4   \n",
       "4       0            0            0         13373.5                 6   \n",
       "\n",
       "   sellingprice  \n",
       "0       12000.0  \n",
       "1       14100.0  \n",
       "2       20800.0  \n",
       "3       22100.0  \n",
       "4       14000.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.1 Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import joblib\n",
    "\n",
    "# 1.2 Konstanten\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH_CLEAN = \"../data/processed/cars_features_no_mmr_reduced.csv\"\n",
    "\n",
    "# 1.3 Einlesen des bereinigten Datensatzes\n",
    "df_cleaned = pd.read_csv(DATA_PATH_CLEAN)\n",
    "\n",
    "# 1.4 Erster Ueberblick\n",
    "print(f\"Shape des bereinigten DataFrames: {df_cleaned.shape}\\n\")\n",
    "display(df_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef80b1e4",
   "metadata": {},
   "source": [
    "## 2. Train-/Test-Split\n",
    "In diesem Kapitel werden die Merkmale und die Zielvariable definiert und der Datensatz in Trainings- und Testset im Verhältnis 80/20 aufgeteilt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f473e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (73249, 21), X_test: (18313, 21)\n",
      "y_train: (73249,), y_test: (18313,)\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Merkmale (X) und Ziel (y) definieren\n",
    "X = df_cleaned.drop(\"sellingprice\", axis=1)\n",
    "y = df_cleaned[\"sellingprice\"]\n",
    "\n",
    "# 2.2 Aufteilen in Trainings- und Testset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Kontrolle der Formen\n",
    "print(f\"X_train: {X_train.shape}, X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}, y_test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3ca44",
   "metadata": {},
   "source": [
    "## 3. Preprocessing-Pipeline\n",
    "Dieser Abschnitt definiert und baut die Vorverarbeitungs-Pipeline für numerische und kategoriale Features mithilfe von Imputer, Skalierer und One-Hot-Encoding auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7905841c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerische Features: ['year', 'condition', 'odometer', 'sale_year', 'sale_month', 'sale_day', 'sale_weekday', 'avg_price_state', 'has_sport', 'has_limited', 'has_lx', 'has_se', 'has_touring', 'has_premium', 'miles_per_year', 'color_popularity']\n",
      "Kategoriale Features: ['body', 'transmission', 'color', 'interior', 'season']\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Numerische und kategoriale Features identifizieren\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Numerische Features:\", numeric_features)\n",
    "print(\"Kategoriale Features:\", categorical_features)\n",
    "\n",
    "# 3.2 Pipelines definieren\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# 3.3 ColumnTransformer erstellen\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b37892",
   "metadata": {},
   "source": [
    "## 4. Baseline-Modelle & Cross-Validation\n",
    "In diesem Abschnitt werden zwei Baseline-Modelle (Lineare Regression und Random Forest) mit 5-fach Kreuzvalidierung auf den Trainingsdaten evaluiert. Als Metrik wird der negative Root Mean Squared Error (neg_root_mean_squared_error) verwendet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1108e145",
   "metadata": {},
   "source": [
    "### 4.1 Lineare Regression: Pipeline und 5-fach CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e2142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE (Linear Regression): 2746.44 (+/- 15.45)\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "scores_lr = cross_val_score(\n",
    "    pipe_lr,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"CV RMSE (Linear Regression): {(-scores_lr).mean():.2f} (+/- {scores_lr.std():.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32513a5",
   "metadata": {},
   "source": [
    "### 4.2 Random Forest: Pipeline und 5-fach CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f22346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE (Random Forest): 2452.95 (+/- 22.81)\n"
     ]
    }
   ],
   "source": [
    "pipe_rf = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(random_state=RANDOM_STATE, n_jobs=-1))\n",
    "])\n",
    "\n",
    "scores_rf = cross_val_score(\n",
    "    pipe_rf,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"CV RMSE (Random Forest): {(-scores_rf).mean():.2f} (+/- {scores_rf.std():.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aac6e31",
   "metadata": {},
   "source": [
    "## 4. Ergebnisse der Kreuzvalidierung\n",
    "\n",
    "| Modell                | CV RMSE        | Std. Dev.    |\n",
    "|-----------------------|----------------|--------------|\n",
    "| Lineare Regression    | 2 746.44       | ± 15.45      |\n",
    "| Random Forest         | 2 452.95       | ± 22.81      |\n",
    "\n",
    "**Interpretation:**  \n",
    "- Der Random Forest erzielt mit einem durchschnittlichen RMSE von **2 452.95** eine deutlich bessere Vorhersagegüte als die Lineare Regression (RMSE **2 746.44**).  \n",
    "- Die höhere Streuung der RF-Ergebnisse (± 22.81 vs. ± 15.45) deutet auf eine etwas variablere Performance zwischen den Folds hin, bleibt jedoch im Rahmen.  \n",
    "- Insgesamt spricht das niedrigere RMSE des Random Forest für dessen Verwendung als baselines Modell im weiteren Verlauf.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87019240",
   "metadata": {},
   "source": [
    "## 5. Modelltraining & Evaluation\n",
    "In diesem Kapitel werden beide Modelle auf dem vollständigen Trainingsset trainiert, Vorhersagen auf Trainings- und Testset erstellt und die Metriken MAE, RMSE und R² berechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c20d5",
   "metadata": {},
   "source": [
    "### 5.0: Vorbereitung calc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bfac5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a1d8f6",
   "metadata": {},
   "source": [
    "### 5.1 Linear Regression: Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d983e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "  Train -> MAE: 2122.81, RMSE: 2743.33, R²: 0.6922\n",
      "  Test  -> MAE: 2115.34, RMSE: 2725.81, R²: 0.6967\n"
     ]
    }
   ],
   "source": [
    "# Pipeline erstellen und trainieren\n",
    "pipe_lr = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train_lr = pipe_lr.predict(X_train)\n",
    "y_pred_test_lr  = pipe_lr.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "mae_tr_lr, rmse_tr_lr, r2_tr_lr = calc_metrics(y_train, y_pred_train_lr)\n",
    "mae_te_lr,  rmse_te_lr,  r2_te_lr  = calc_metrics(y_test,  y_pred_test_lr)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"Linear Regression:\")\n",
    "print(f\"  Train -> MAE: {mae_tr_lr:.2f}, RMSE: {rmse_tr_lr:.2f}, R²: {r2_tr_lr:.4f}\")\n",
    "print(f\"  Test  -> MAE: {mae_te_lr:.2f}, RMSE: {rmse_te_lr:.2f}, R²: {r2_te_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b640b",
   "metadata": {},
   "source": [
    "### 5.2 Random Forest: Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d9e7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "  Train -> MAE: 671.21, RMSE: 912.90, R²: 0.9659\n",
      "  Test  -> MAE: 1804.50, RMSE: 2441.23, R²: 0.7567\n"
     ]
    }
   ],
   "source": [
    "# Pipeline erstellen und trainieren\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1\n",
    "    ))\n",
    "])\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen\n",
    "y_pred_train_rf = pipe_rf.predict(X_train)\n",
    "y_pred_test_rf  = pipe_rf.predict(X_test)\n",
    "\n",
    "# Metriken berechnen\n",
    "mae_tr_rf, rmse_tr_rf, r2_tr_rf = calc_metrics(y_train, y_pred_train_rf)\n",
    "mae_te_rf,  rmse_te_rf,  r2_te_rf  = calc_metrics(y_test,  y_pred_test_rf)\n",
    "\n",
    "# Ergebnisse ausgeben\n",
    "print(\"Random Forest:\")\n",
    "print(f\"  Train -> MAE: {mae_tr_rf:.2f}, RMSE: {rmse_tr_rf:.2f}, R²: {r2_tr_rf:.4f}\")\n",
    "print(f\"  Test  -> MAE: {mae_te_rf:.2f}, RMSE: {rmse_te_rf:.2f}, R²: {r2_te_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b665ada",
   "metadata": {},
   "source": [
    "## 5. Ergebnisse des Modelltrainings & Evaluation\n",
    "\n",
    "| Modell               | Set    | MAE      | RMSE     | R²      |\n",
    "|----------------------|--------|----------|----------|---------|\n",
    "| **Lineare Regression** | Train  | 2 122.81 | 2 743.33 | 0.6922  |\n",
    "|                      | Test   | 2 115.34 | 2 725.81 | 0.6967  |\n",
    "| **Random Forest**     | Train  |   671.21 |   912.90 | 0.9659  |\n",
    "|                      | Test   | 1 804.50 | 2 441.23 | 0.7567  |\n",
    "\n",
    "**Interpretation:**  \n",
    "- **Lineare Regression**  \n",
    "  - Die Performance auf Training und Test ist nahezu identisch (ΔRMSE ≈ 17.5), R²-Werte um 0.69 zeigen moderate Modellgüte ohne Over- oder Underfitting.  \n",
    "  - Der Fehler liegt bei knapp 2 700 USD RMSE – dieses Modell erklärt rund 69 % der Varianz der Verkaufspreise.\n",
    "\n",
    "- **Random Forest**  \n",
    "  - Sehr niedrige Fehler auf den Trainingsdaten (RMSE ≈ 913, R² ≈ 0.97) im Vergleich zum Testset (RMSE ≈ 2 441, R² ≈ 0.76) deutet auf Overfitting hin.  \n",
    "  - Dennoch übertrifft der Random Forest die lineare Regression deutlich auf dem Testset (RMSE um ~280 USD geringer, R² um ~0.06 höher).\n",
    "\n",
    "**Schlussfolgerung:**  \n",
    "- Die lineare Regression liefert eine stabile, aber weniger genaue Vorhersage.  \n",
    "- Der Random Forest erreicht bessere Genauigkeit auf neuen Daten, zeigt jedoch Overfitting-Tendenzen.  \n",
    "- Für produktive Nutzung sollte ggf. das Random Forest-Modell weiter abgestimmt (z. B. Hyperparameter-Tuning, Regularisierung) oder alternative Modelle (z. B. Gradient Boosting) geprüft werden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e964f9",
   "metadata": {},
   "source": [
    "## 6. Feature Importance je Modell\n",
    "Ermittlung und Darstellung der wichtigsten Merkmale für die Lineare Regression (über Koeffizienten) und für den Random Forest (über `feature_importances_`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86f0ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features (Lineare Regression):\n",
      "                feature  importance\n",
      "cat__interior_off-white 3706.695862\n",
      "    cat__body_Hatchback 3123.800793\n",
      "        cat__color_pink 2822.760402\n",
      "          cat__body_suv 2629.268936\n",
      "      cat__body_Minivan 2125.148139\n",
      "          cat__body_SUV 2099.717886\n",
      "   cat__color_off-white 2094.526383\n",
      "        cat__body_Sedan 2085.124716\n",
      "              num__year 2021.848934\n",
      "   cat__interior_yellow 1921.087853\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Feature-Namen aus dem Preprocessor extrahieren\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Sicherstellen, dass die Pipeline trainiert ist\n",
    "pipe_lr.fit(X_train, y_train)\n",
    "pipe_rf.fit(X_train, y_train)\n",
    "\n",
    "# 6.2 Lineare Regression: Koeffizienten\n",
    "coef = pipe_lr.named_steps[\"model\"].coef_\n",
    "import pandas as pd\n",
    "\n",
    "fi_lr = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": np.abs(coef)\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"Top 10 Features (Lineare Regression):\")\n",
    "print(fi_lr.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e81cea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Features (Random Forest):\n",
      "              feature  importance\n",
      "        num__odometer    0.406584\n",
      "            num__year    0.145629\n",
      "        cat__body_SUV    0.128833\n",
      "       num__condition    0.060692\n",
      "  num__miles_per_year    0.039499\n",
      "    cat__body_Minivan    0.029617\n",
      " num__avg_price_state    0.029565\n",
      "        num__sale_day    0.026950\n",
      "num__color_popularity    0.013841\n",
      "    num__sale_weekday    0.012602\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Random Forest: Feature Importances\n",
    "importances = pipe_rf.named_steps[\"model\"].feature_importances_\n",
    "\n",
    "fi_rf = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"importance\": importances\n",
    "}).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features (Random Forest):\")\n",
    "print(fi_rf.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2864574a",
   "metadata": {},
   "source": [
    "## 6. Zusammenfassung der Feature Importances und Massnahmen gegen Overfitting\n",
    "\n",
    "### Wichtige Erkenntnisse\n",
    "- **Lineare Regression**  \n",
    "  - Die Top-Koeffizienten entstammen primär kategorialen Variablen, etwa `interior_off-white`, `body_Hatchback` und `color_pink`, gefolgt von `year`.  \n",
    "  - Numerische Merkmale wie `odometer` tauchen in den Top-10 der LR-Koeffizienten nicht auf, obwohl sie im RF wichtig sind – hier scheint die LR die Einflüsse anders zu gewichten.\n",
    "\n",
    "- **Random Forest**  \n",
    "  - Dominant ist das Merkmal `odometer` (ca. 41 % des Gesamt-Importance-Gewichts), gefolgt von `year` (15 %) und `body_SUV` (13 %).  \n",
    "  - `condition`, `miles_per_year` und `avg_price_state` bringen ebenfalls einen messbaren Beitrag.  \n",
    "\n",
    "### Potenzielle Massnahmen gegen Overfitting\n",
    "1. **Feature-Reduktion**  \n",
    "   - **Remove Rare Categories**: Kategorien mit sehr kleinem Vorkommen (z. B. `interior_yellow`, `color_pink`) zusammenfassen oder in eine \"Other\"-Gruppe überführen, um Rauschen zu verringern.  \n",
    "   - **Low-Importance Features**: Features mit fast null Importance im RF (z. B. `sale_weekday`, farbliche Kategorien jenseits der Top-10) ausschliessen und erneut validieren.\n",
    "\n",
    "2. **Regularisierung / Modellkomplexität**  \n",
    "   - **Max Depth / Min Samples**: Für den RF tieferes `max_depth` und höheres `min_samples_leaf` wählen, um den Einfluss des dominanten `odometer`-Merkmals abzumildern.  \n",
    "   - **Max Features**: `max_features=\"sqrt\"` oder kleiner einstellen, damit nicht in jedem Split fast ausschliesslich `odometer` und `year` ausgewählt werden.\n",
    "\n",
    "3. **Feature-Engineering**  \n",
    "   - **Interaktionsmerkmale**: Prüfen, ob gezielte Interaktionen (z. B. `odometer * condition`) sinnvoll sind und Overfitting nicht verschärfen.  \n",
    "   - **Binning**: Starker Einfluss von `odometer` könnte in Diskretisierung (z. B. Kilometer-Bins) gegossen werden, um Ausreisserrobustheit zu erhöhen.\n",
    "\n",
    "4. **Cross-Validation & Ensembling**  \n",
    "   - **Stärkere CV**: 10-fach-CV oder wiederholte CV (RepeatedKFold), um stabilere Schätzungen zu erhalten.  \n",
    "   - **Ensemble aus unterschiedlichen Modellen**: Lineare Regression und RF kombinieren (z. B. durch Stacking), um die Ausprägungen einzelner Modelle auszubalancieren.\n",
    "\n",
    "5. **Alternative Modelle**  \n",
    "   - **Gradient Boosting** (z. B. LightGBM mit Regularisierung über `lambda_l1`, `lambda_l2`): Oft robuster gegen ein dominantes Merkmal wie `odometer`.  \n",
    "   - **Lasso / ElasticNet**: Für die lineare Variante, um unwichtige Koeffizienten direkt auf null zu setzen.\n",
    "\n",
    "---\n",
    "\n",
    "Durch gezieltes Entfernen oder Zusammenfassen weniger informativer Kategorien sowie Anpassung der RF-Hyperparameter kann die Modellkomplexität reduziert und Overfitting nachhaltig bekämpft werden. Anschliessend empfiehlt sich eine erneute Validierung (z. B. Repeated CV), um den Effekt der Änderungen zu prüfen.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
