{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd92c292",
   "metadata": {},
   "source": [
    "# Notebook 06: Modelloptimierung & Overfitting-Reduktion\n",
    "\n",
    "In diesem Notebook werden verschiedene Strategien zur Verbesserung der Modellgeneralisation umgesetzt. Dazu gehören Feature-Selektion basierend auf Importance, Hyperparameter-Tuning des Random Forest mittels RandomizedSearchCV, ein Vergleich mit einem Gradient-Boosting-Modell sowie optionales Ensembling. Ziel ist die Reduktion von Overfitting und die Steigerung der Vorhersagegenauigkeit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77404b74",
   "metadata": {},
   "source": [
    "## 1. Setup & Dateneinlese\n",
    "In diesem Kapitel werden die benoetigten Bibliotheken importiert, Konstanten definiert und der bereinigte Datensatz eingelesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d24794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape des DataFrames: (91562, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>condition</th>\n",
       "      <th>odometer</th>\n",
       "      <th>sale_year</th>\n",
       "      <th>sale_month</th>\n",
       "      <th>sale_day</th>\n",
       "      <th>sale_weekday</th>\n",
       "      <th>body</th>\n",
       "      <th>transmission</th>\n",
       "      <th>color</th>\n",
       "      <th>...</th>\n",
       "      <th>season</th>\n",
       "      <th>has_sport</th>\n",
       "      <th>has_limited</th>\n",
       "      <th>has_lx</th>\n",
       "      <th>has_se</th>\n",
       "      <th>has_touring</th>\n",
       "      <th>has_premium</th>\n",
       "      <th>miles_per_year</th>\n",
       "      <th>color_popularity</th>\n",
       "      <th>sellingprice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5559.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>automatic</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5559.0</td>\n",
       "      <td>4</td>\n",
       "      <td>12000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45035.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>SUV</td>\n",
       "      <td>automatic</td>\n",
       "      <td>gray</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22517.5</td>\n",
       "      <td>3</td>\n",
       "      <td>14100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>46.0</td>\n",
       "      <td>20035.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>SUV</td>\n",
       "      <td>automatic</td>\n",
       "      <td>gray</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10017.5</td>\n",
       "      <td>3</td>\n",
       "      <td>20800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>46.0</td>\n",
       "      <td>41115.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>SUV</td>\n",
       "      <td>automatic</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20557.5</td>\n",
       "      <td>4</td>\n",
       "      <td>22100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26747.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>Hatchback</td>\n",
       "      <td>automatic</td>\n",
       "      <td>red</td>\n",
       "      <td>...</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13373.5</td>\n",
       "      <td>6</td>\n",
       "      <td>14000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  condition  odometer  sale_year  sale_month  sale_day  sale_weekday  \\\n",
       "0  2015        2.0    5559.0       2015           1        13             1   \n",
       "1  2012       35.0   45035.0       2014          12        18             3   \n",
       "2  2012       46.0   20035.0       2014          12        18             3   \n",
       "3  2012       46.0   41115.0       2014          12        18             3   \n",
       "4  2012        3.0   26747.0       2014          12        17             2   \n",
       "\n",
       "        body transmission  color  ...  season  has_sport has_limited  has_lx  \\\n",
       "0      Sedan    automatic  white  ...  Winter          0           0       0   \n",
       "1        SUV    automatic   gray  ...  Winter          0           1       0   \n",
       "2        SUV    automatic   gray  ...  Winter          0           0       0   \n",
       "3        SUV    automatic  white  ...  Winter          0           0       0   \n",
       "4  Hatchback    automatic    red  ...  Winter          0           0       0   \n",
       "\n",
       "   has_se  has_touring  has_premium  miles_per_year  color_popularity  \\\n",
       "0       1            0            0          5559.0                 4   \n",
       "1       0            0            0         22517.5                 3   \n",
       "2       1            0            0         10017.5                 3   \n",
       "3       1            0            0         20557.5                 4   \n",
       "4       0            0            0         13373.5                 6   \n",
       "\n",
       "   sellingprice  \n",
       "0       12000.0  \n",
       "1       14100.0  \n",
       "2       20800.0  \n",
       "3       22100.0  \n",
       "4       14000.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.1 Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import joblib\n",
    "\n",
    "# 1.2 Konstanten\n",
    "RANDOM_STATE = 42\n",
    "DATA_PATH = \"../data/processed/cars_features_no_mmr_reduced.csv\"\n",
    "\n",
    "# 1.3 Einlesen des bereinigten Datensatzes\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# 1.4 Erster Überblick\n",
    "print(f\"Shape des DataFrames: {df.shape}\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638b6a11",
   "metadata": {},
   "source": [
    "## 2. Preprocessing-Pipeline übernehmen\n",
    "In diesem Schritt werden die numerischen und kategorialen Merkmale identifiziert und die Vorverarbeitungs-Pipeline aus den vorherigen Notebooks wiederverwendet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a6c5fedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerische Features: ['year', 'condition', 'odometer', 'sale_year', 'sale_month', 'sale_day', 'sale_weekday', 'avg_price_state', 'has_sport', 'has_limited', 'has_lx', 'has_se', 'has_touring', 'has_premium', 'miles_per_year', 'color_popularity']\n",
      "Kategoriale Features: ['body', 'transmission', 'color', 'interior', 'season']\n"
     ]
    }
   ],
   "source": [
    "# 2.1 Numerische und kategoriale Features identifizieren\n",
    "numeric_features = df.select_dtypes(include=[np.number]).drop(\"sellingprice\", axis=1).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "print(\"Numerische Features:\", numeric_features)\n",
    "print(\"Kategoriale Features:\", categorical_features)\n",
    "\n",
    "# 2.2 Pipelines definieren\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# 2.3 ColumnTransformer erstellen\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c0b85",
   "metadata": {},
   "source": [
    "### 3. Hyperparameter-Tuning für Random Forest (ressourcenschonend)\n",
    "Dieser Abschnitt führt das Tuning auf einer Stichprobe und mit reduzierter CV- und Suchkonfiguration durch, um Laufzeit zu verkürzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b75a8ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beste Parameter: {'model__n_estimators': 150, 'model__min_samples_leaf': 2, 'model__max_features': 0.5, 'model__max_depth': 20}\n",
      "Bestes CV RMSE (Stichprobe): 2523.74\n"
     ]
    }
   ],
   "source": [
    "# 3.1 Train-/Test-Split (falls noch nicht erfolgt)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(\"sellingprice\", axis=1)\n",
    "y = df[\"sellingprice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 3.2 Stichprobe aus dem Trainingsset entnehmen (z.B. 30%)\n",
    "X_tune, _, y_tune, _ = train_test_split(\n",
    "    X_train, y_train, train_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 3.3 Pipeline mit Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "pipe_rf = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 3.4 Parameterbereich festlegen\n",
    "param_dist = {\n",
    "    \"model__n_estimators\": [50, 100, 150],\n",
    "    \"model__max_depth\": [None, 10, 20],\n",
    "    \"model__min_samples_leaf\": [1, 2],\n",
    "    \"model__max_features\": [\"sqrt\", 0.5]\n",
    "}\n",
    "\n",
    "# 3.5 RandomizedSearchCV konfigurieren (cv=3, n_iter=5)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rs_cv = RandomizedSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=5,                      # nur 5 Kombinationen\n",
    "    cv=3,                          # 3-fach CV\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=1                       # single-threaded\n",
    ")\n",
    "\n",
    "# 3.6 Tuningsuche auf der Stichprobe ausführen\n",
    "rs_cv.fit(X_tune, y_tune)\n",
    "\n",
    "# 3.7 Beste Parameter und Score anzeigen\n",
    "print(\"Beste Parameter:\", rs_cv.best_params_)\n",
    "print(f\"Bestes CV RMSE (Stichprobe): { -rs_cv.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377e73f6",
   "metadata": {},
   "source": [
    "## 4. Evaluation des getunten Random Forest\n",
    "In diesem Abschnitt wird das Modell mit den besten Hyperparametern auf dem gesamten Trainingsset trainiert und auf dem Testset evaluiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "53b33ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gefundene Parameter: {'model__n_estimators': 150, 'model__min_samples_leaf': 2, 'model__max_features': 0.5, 'model__max_depth': 20}\n"
     ]
    }
   ],
   "source": [
    "# Definition der Metrikfunktion (einmalig irgendwo zu Beginn)\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "def calc_metrics(y_true, y_pred):\n",
    "    mae  = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2   = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "# Beispiel: So sieht rs_cv.best_params_ aus und kommt nur aus param_dist\n",
    "print(\"Gefundene Parameter:\", rs_cv.best_params_)\n",
    "# z.B.: {'model__n_estimators': 150, 'model__min_samples_leaf': 2, \n",
    "#        'model__max_features': 0.5, 'model__max_depth': 20}\n",
    "\n",
    "# Damit ist sichergestellt, dass nur aus \n",
    "# [50, 100, 150], [None, 10, 20], [1, 2], ['sqrt', 0.5] gewählt wird.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "836e4361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest (getunt):\n",
      "  Train -> MAE: 1126.92, RMSE: 1538.00, R²: 0.9033\n",
      "  Test  -> MAE: 1781.53, RMSE: 2405.00, R²: 0.7639\n"
     ]
    }
   ],
   "source": [
    "# 4.1 Pipeline mit den besten Parametern\n",
    "best_params = rs_cv.best_params_\n",
    "pipe_rf_tuned = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=best_params[\"model__n_estimators\"],\n",
    "        max_depth=best_params[\"model__max_depth\"],\n",
    "        min_samples_leaf=best_params[\"model__min_samples_leaf\"],\n",
    "        max_features=best_params[\"model__max_features\"],\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 4.2 Training auf dem vollen Trainingsset\n",
    "pipe_rf_tuned.fit(X_train, y_train)\n",
    "\n",
    "# 4.3 Vorhersagen\n",
    "y_pred_train_tuned = pipe_rf_tuned.predict(X_train)\n",
    "y_pred_test_tuned  = pipe_rf_tuned.predict(X_test)\n",
    "\n",
    "# 4.4 Metriken berechnen\n",
    "mae_tr, rmse_tr, r2_tr = calc_metrics(y_train, y_pred_train_tuned)\n",
    "mae_te, rmse_te, r2_te = calc_metrics(y_test,  y_pred_test_tuned)\n",
    "\n",
    "# 4.5 Ergebnisse ausgeben\n",
    "print(\"Random Forest (getunt):\")\n",
    "print(f\"  Train -> MAE: {mae_tr:.2f}, RMSE: {rmse_tr:.2f}, R²: {r2_tr:.4f}\")\n",
    "print(f\"  Test  -> MAE: {mae_te:.2f}, RMSE: {rmse_te:.2f}, R²: {r2_te:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Vergleich mit Gradient Boosting (sklearn)\n",
    "Ein GradientBoostingRegressor wird mit einer moderaten Lernrate und Tiefe aufgesetzt, um Regularisierung und Boosting-Effekte zu nutzen. Das Modell wird per 5-facher Kreuzvalidierung geprüft und anschliessend auf Trainings- und Testset evaluiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a614015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSE (GradientBoosting): 2539.35 ±17.85\n",
      "\n",
      "GradientBoostingRegressor:\n",
      "  Train -> MAE: 1913.80, RMSE: 2527.95, R²: 0.7387\n",
      "  Test  -> MAE: 1913.43, RMSE: 2531.92, R²: 0.7383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Pipeline mit GradientBoostingRegressor\n",
    "pipe_gbr = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=3,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 5-fach CV auf Trainingsdaten\n",
    "scores_gbr = cross_val_score(\n",
    "    pipe_gbr,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    n_jobs=1\n",
    ")\n",
    "print(f\"CV RMSE (GradientBoosting): {(-scores_gbr).mean():.2f} ±{scores_gbr.std():.2f}\")\n",
    "\n",
    "# Training und Evaluation auf Trainings- und Testset\n",
    "pipe_gbr.fit(X_train, y_train)\n",
    "y_pred_train_gbr = pipe_gbr.predict(X_train)\n",
    "y_pred_test_gbr  = pipe_gbr.predict(X_test)\n",
    "\n",
    "mae_tr_gbr, rmse_tr_gbr, r2_tr_gbr = calc_metrics(y_train, y_pred_train_gbr)\n",
    "mae_te_gbr, rmse_te_gbr, r2_te_gbr = calc_metrics(y_test,  y_pred_test_gbr)\n",
    "\n",
    "print(\"\\nGradientBoostingRegressor:\")\n",
    "print(f\"  Train -> MAE: {mae_tr_gbr:.2f}, RMSE: {rmse_tr_gbr:.2f}, R²: {r2_tr_gbr:.4f}\")\n",
    "print(f\"  Test  -> MAE: {mae_te_gbr:.2f}, RMSE: {rmse_te_gbr:.2f}, R²: {r2_te_gbr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a66922",
   "metadata": {},
   "source": [
    "## 6. Erweiterte Feature-Erstellung\n",
    "In diesem Abschnitt werden verschiedene neue Merkmale abgeleitet, um nichtlineare, zeitliche und relative Effekte abzubilden sowie Ausstattungsvielfalt zu erfassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2d5be3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erweiterte Features hinzugefügt. Aktuelle Spaltenzahl: 37\n",
      "Odometer-Bins: [0, 20000, 50000, 100000, np.float64(170648.0)]\n",
      "Eindeutige age_bin-Werte: [np.int64(0), np.int64(1), np.int64(2), np.int64(3)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 6.1 Fahrzeugalter\n",
    "df[\"age\"] = df[\"sale_year\"] - df[\"year\"]\n",
    "\n",
    "# 6.2 Zyklische Repräsentation von Monat und Wochentag\n",
    "df[\"month_sin\"]   = np.sin(2 * np.pi * df[\"sale_month\"] / 12)\n",
    "df[\"month_cos\"]   = np.cos(2 * np.pi * df[\"sale_month\"] / 12)\n",
    "df[\"weekday_sin\"] = np.sin(2 * np.pi * df[\"sale_weekday\"] / 7)\n",
    "df[\"weekday_cos\"] = np.cos(2 * np.pi * df[\"sale_weekday\"] / 7)\n",
    "\n",
    "# 6.3 Wochenend-Flag\n",
    "df[\"is_weekend\"] = (df[\"sale_weekday\"] >= 5).astype(int)\n",
    "\n",
    "# 6.4 Anzahl besonderer Ausstattungsmerkmale\n",
    "trim_flags = [\"has_sport\", \"has_limited\", \"has_lx\", \"has_se\", \"has_touring\", \"has_premium\"]\n",
    "df[\"special_count\"] = df[trim_flags].sum(axis=1)\n",
    "\n",
    "# 6.5 Interaktion Zustand × Laufleistung\n",
    "df[\"cond_x_mpy\"] = df[\"condition\"] * df[\"miles_per_year\"]\n",
    "\n",
    "# 6.6 Log-Transformationen\n",
    "df[\"log_odometer\"]     = np.log1p(df[\"odometer\"])\n",
    "\n",
    "# 6.7 Länge der Kategorienschlüssel\n",
    "df[\"body_len\"]     = df[\"body\"].str.len()\n",
    "df[\"color_len\"]    = df[\"color\"].str.len()\n",
    "df[\"interior_len\"] = df[\"interior\"].str.len()\n",
    "\n",
    "# 6.8 Quartals-Dummy\n",
    "df[\"sale_quarter\"] = ((df[\"sale_month\"] - 1) // 3 + 1).astype(int)\n",
    "\n",
    "# 6.9 Binning von odometer – korrigierte Bin-Grenzen\n",
    "max_odo = df[\"odometer\"].max()\n",
    "odo_bins = [0, 20000, 50000, 100000, max_odo]\n",
    "df[\"odo_bin\"] = pd.cut(\n",
    "    df[\"odometer\"],\n",
    "    bins=odo_bins,\n",
    "    labels=False,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# 6.10 Binning von age mit Duplikate-Entfernung\n",
    "df[\"age_bin\"] = pd.qcut(\n",
    "    df[\"age\"],\n",
    "    q=5,\n",
    "    labels=False,\n",
    "    duplicates=\"drop\"\n",
    ")\n",
    "\n",
    "print(\"Erweiterte Features hinzugefügt. Aktuelle Spaltenzahl:\", df.shape[1])\n",
    "print(\"Odometer-Bins:\", odo_bins)\n",
    "print(\"Eindeutige age_bin-Werte:\", sorted(df[\"age_bin\"].dropna().unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e1abcf",
   "metadata": {},
   "source": [
    "### 7. Random Forest: Re-Training mit erweiterten Features\n",
    "Nach der Aktualisierung der Pipeline und des neuen Train-/Test-Splits wird der Random Forest mit den getunten Hyperparametern erneut trainiert und evaluiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5175df60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest mit erweiterten Features:\n",
      "  Train -> MAE: 1096.89, RMSE: 1498.45, R²: 0.9082\n",
      "  Test  -> MAE: 1788.88, RMSE: 2414.38, R²: 0.7620\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 7.1 Neue Feature-Listen\n",
    "numeric_features     = df.select_dtypes(include=[np.number]).drop(\"sellingprice\", axis=1).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# 7.2 Aktualisierte Preprocessing-Pipeline\n",
    "numeric_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_pipeline, numeric_features),\n",
    "    (\"cat\", categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "# 7.3 Neuer Train-/Test-Split\n",
    "X = df.drop(\"sellingprice\", axis=1)\n",
    "y = df[\"sellingprice\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# 7.4 Pipeline mit getunten RF-Hyperparametern\n",
    "pipe_rf_final = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=best_params[\"model__n_estimators\"],\n",
    "        max_depth=best_params[\"model__max_depth\"],\n",
    "        min_samples_leaf=best_params[\"model__min_samples_leaf\"],\n",
    "        max_features=best_params[\"model__max_features\"],\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 7.5 Training\n",
    "pipe_rf_final.fit(X_train, y_train)\n",
    "\n",
    "# 7.6 Vorhersagen\n",
    "y_pred_train = pipe_rf_final.predict(X_train)\n",
    "y_pred_test  = pipe_rf_final.predict(X_test)\n",
    "\n",
    "# 7.7 Evaluation\n",
    "mae_tr, rmse_tr, r2_tr = calc_metrics(y_train, y_pred_train)\n",
    "mae_te, rmse_te, r2_te = calc_metrics(y_test,  y_pred_test)\n",
    "\n",
    "# 7.8 Ergebnisse ausgeben\n",
    "print(\"Random Forest mit erweiterten Features:\")\n",
    "print(f\"  Train -> MAE: {mae_tr:.2f}, RMSE: {rmse_tr:.2f}, R²: {r2_tr:.4f}\")\n",
    "print(f\"  Test  -> MAE: {mae_te:.2f}, RMSE: {rmse_te:.2f}, R²: {r2_te:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11393773",
   "metadata": {},
   "source": [
    "## Vergleich der RF-Varianten ohne MMR\n",
    "\n",
    "| Version                                | Train RMSE | Test RMSE | Test R²  |\n",
    "|----------------------------------------|------------|-----------|----------|\n",
    "| **1. Ungetunt**                        | 912.90     | 2 441.23  | 0.7567   |\n",
    "| **2. Getunt (Hyperparameter-Optimierung)** | 1 538.00   | 2 405.00  | 0.7639   |\n",
    "| **3. Getunt + erweiterte Features**    | 1 498.45   | 2 414.38  | 0.7620   |\n",
    "\n",
    "**Bestes Modell nach MMR-Entfernung:**  \n",
    "Die **Hyperparameter-getunte Variante** (Version 2) erzielt mit **Test-RMSE ≈ 2 405** und **Test-R² ≈ 0.7639** die besten Werte. Sie reduziert sowohl den Test-RMSE als auch den Overfitting-Gap im Vergleich zum ungetunten Modell und bleibt zugleich genauer als die erweiterte-Feature-Version.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
